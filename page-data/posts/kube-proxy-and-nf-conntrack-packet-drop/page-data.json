{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/posts/kube-proxy-and-nf-conntrack-packet-drop/","result":{"data":{"post":{"html":"<h2 id=\"tl-dr\" style=\"position:relative;\"><a href=\"#tl-dr\" aria-label=\"tl dr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL; DR</h2>\n<p>kube-proxy 가 기동될 때 kernel의 nf_conntrack_max 파라미터 값이 업데이트될 수 있다</p>\n<h2 id=\"이슈-원인\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%8A%88-%EC%9B%90%EC%9D%B8\" aria-label=\"이슈 원인 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이슈 원인</h2>\n<p>전 회사에서 근무 도중 다른 팀에서 간헐적으로 극소수의 요청이 실패하는 경우가 있었으나 APM 상에서는 이슈가 없던 상황이었다 <br>\n원인을 찾던 도중 k8s ingress 노드에서 <strong>nf_conntrack:table full, dropping packet</strong> 와 같은 에러 로그가 발생하는 것을 확인하였다 <br>\n아마 기본적으로 nf_conntrack과 커널 파라미터 등이 튜닝이 되어 있었으나 요청 peak가 몰리는 상황이 발생하여 이슈가 된 것으로 보였다 <br>\n인프라 엔지니어 분께 요청을 드려 관련 ingress 노드들의 nf_conntrack_max 값을 늘려두었다 <br>\n(nf_conntrack와 관련해서는 <a href=\"https://blog.naver.com/n_cloudplatform/221638712887\">네이버 기술 블로그</a>를 참고하는 것이 좋을 것 같다)</p>\n<p>이후 증상이 완화되어 문제가 해결된 줄 알았으나 몇 일이 지난 이후 동일 증상이 발생하는 것을 확인할 수 있었다 <br>\nOS 버전 업데이트 / 하드웨어 이슈 등으로 투입이 제외되었다가 재부팅 이후 다시 투입이 되었던 노드들이었고 nf_conntrack_max 값이 늘려둔 값과는 다른 값으로 설정되어 있었다</p>\n<p>/etc/sysctl.conf 쪽에 설정이 누락된 것은 아니였고 실제로 재부팅된 직후에는 nf_conntrack_max 값이 의도한대로 설정되어 있는 것을 확인하였다 <br>\n로그를 좀 더 찾아보니 kube-proxy 쪽에서 아래와 같은 로그를 확인할 수 있었다(당시 실제 로그는 아님)</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">I0322 02:18:07.397120       1 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_max' to 2097120\nI0322 02:18:07.397214       1 conntrack.go:52] Setting nf_conntrack_max to 2097120</code></pre></div>\n<p>원인을 파악하여 클라우드 엔지니어 분께 관련 설정 변경을 요청드리고 이후에는 <strong>nf_conntrack:table full, dropping packet</strong> 로그가 발생하지 않는 것을 확인할 수 있었다</p>","excerpt":"TL; DR kube-proxy 가 기동될 때 kernel의 nf_conntrack_max 파라미터 값이 업데이트될 수 있다 이슈 원인 전 회사에서 근무 도중 다른 팀에서 간헐적으로 극소수의 요청이 실패하는 경우가 있었으나 APM…","timeToRead":1,"fields":{"slug":"/posts/kube-proxy-and-nf-conntrack-packet-drop/"},"frontmatter":{"tags":["k8s","kube-proxy","nf-conntrack"],"author":{"jsonId":"cprayer","bio":"","twitter":"@fabien0102","avatar":{"children":[{"fixed":{"src":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/b0b39/cprayer.jpg","srcSet":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/b0b39/cprayer.jpg 1x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/93542/cprayer.jpg 1.5x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/aa4d2/cprayer.jpg 2x"}}]}},"title":"nf_conntrack_max 값이 k8s ingress 노드 재부팅 후 의도하지 않은 값으로 업데이트 되는 이슈","updatedDate":"May 18, 2025","image":null}},"recents":{"edges":[{"node":{"fields":{"slug":"/posts/epoll-wait-failed-function-not-implemented/"},"timeToRead":1,"frontmatter":{"title":"netty epoll_wait(..) failed: Function not implemented 에러 이슈 해결 방법","image":null,"author":{"jsonId":"cprayer","avatar":{"children":[{"fixed":{"src":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg","srcSet":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg 1x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/fe190/cprayer.jpg 1.5x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/3e51d/cprayer.jpg 2x"}}]}}}}},{"node":{"fields":{"slug":"/posts/k8s-and-etc-resolv-conf/"},"timeToRead":3,"frontmatter":{"title":"k8s와 /etc/resolv.conf","image":null,"author":{"jsonId":"cprayer","avatar":{"children":[{"fixed":{"src":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg","srcSet":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg 1x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/fe190/cprayer.jpg 1.5x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/3e51d/cprayer.jpg 2x"}}]}}}}},{"node":{"fields":{"slug":"/posts/redis-manually-force-a-failover/"},"timeToRead":1,"frontmatter":{"title":"강제로 레플리카 레디스를 마스터로 승격시키기","image":null,"author":{"jsonId":"cprayer","avatar":{"children":[{"fixed":{"src":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg","srcSet":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg 1x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/fe190/cprayer.jpg 1.5x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/3e51d/cprayer.jpg 2x"}}]}}}}},{"node":{"fields":{"slug":"/posts/hbase-client-dns-excessive-query-issue/"},"timeToRead":2,"frontmatter":{"title":"hbase sharded client 1.2 dns 과다 질의 이슈","image":null,"author":{"jsonId":"cprayer","avatar":{"children":[{"fixed":{"src":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg","srcSet":"/static/5d0fd80a1d7df4f6a3adf452cc763c07/6d45f/cprayer.jpg 1x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/fe190/cprayer.jpg 1.5x,\n/static/5d0fd80a1d7df4f6a3adf452cc763c07/3e51d/cprayer.jpg 2x"}}]}}}}}]}},"pageContext":{"slug":"/posts/kube-proxy-and-nf-conntrack-packet-drop/"}},"staticQueryHashes":[],"slicesMap":{}}